{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모드의 딥러닝 개정 2판\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    }
   ],
   "source": [
    "seed=0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df_pre=pd.read_csv('C:/Users/doimo/pythonDataWorkspace/080228-master/080228-master/deeplearning/dataset/housing.csv', delim_whitespace=True,header=None) #  read_csv 의 인자중 header 를 None 으로 주면 판다스는 인덱스를 자동으로 만들어낸다.delim_whitespace=Trues는 공백을 구분자로 사용한다. [중혁] 스페이스가 아니가 아니라 여러개여도 되는거 같다\n",
    "df=df_pre.sample(frac=1) # sample을 가지고 오는데 frac=1 이기 때문에 100% 가지고 온다. 즉 다 가지고 와서 100% 샘플을 만들기 때문에 그냥 섞어 준다고 보면 된다\n",
    "dataset=df.values\n",
    "\n",
    "print(dataset.shape) # 첫째  column의 개수는 14개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=dataset[:,0:13].astype(float) # [중혁] 0부터 12까지 슬라이싱 된다. 즉 총 13개\n",
    "sub=dataset[:,13].astype(float)\n",
    "\n",
    "x_train, x_test,y_train,y_test = train_test_split(ind,sub,test_size=0.3,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.keras.layers.Input(shape=[13])\n",
    "h=tf.keras.layers.Dense(30,activation='relu')(x)\n",
    "h=tf.keras.layers.Dense(6,activation='relu')(h)\n",
    "h=tf.keras.layers.Dense(6,activation='relu')(h)\n",
    "y=tf.keras.layers.Dense(1)(h) # 0과 1사이가 나오는 것이  아니라 가격을 예측하는 것이기 때문에 y는 activation이 필요 없다\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 688.3627 - accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 386.7010 - accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 238.1286 - accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 199.8802 - accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 191.7860 - accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 168.4429 - accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 134.0264 - accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 102.5871 - accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 82.9240 - accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 72.8253 - accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 65.2992 - accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 62.5620 - accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 61.2860 - accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 59.8845 - accuracy: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 59.2560 - accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 58.3324 - accuracy: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 57.4158 - accuracy: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 56.7339 - accuracy: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 56.0633 - accuracy: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 55.3956 - accuracy: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 54.8610 - accuracy: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 54.4727 - accuracy: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 54.0839 - accuracy: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 53.5696 - accuracy: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 53.1968 - accuracy: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 52.7966 - accuracy: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 52.2303 - accuracy: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 52.0376 - accuracy: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 51.8008 - accuracy: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 51.2479 - accuracy: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 50.9614 - accuracy: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 50.6977 - accuracy: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 50.0664 - accuracy: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 49.8171 - accuracy: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 49.5069 - accuracy: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 48.9591 - accuracy: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 48.5371 - accuracy: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 48.5762 - accuracy: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 48.8127 - accuracy: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 47.8389 - accuracy: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 47.2392 - accuracy: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 47.0762 - accuracy: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 46.4218 - accuracy: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 46.3560 - accuracy: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 45.7517 - accuracy: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 45.6127 - accuracy: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 45.3351 - accuracy: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 45.0791 - accuracy: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 44.7484 - accuracy: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 44.4077 - accuracy: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 44.1132 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19b864e7820>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=tf.keras.models.Model(x,y)\n",
    "model.compile(loss='mse',optimizer='adam', metrics='accuracy')\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "Early_Stopping_callbacks=EarlyStopping(monitor='accuracy', patience=50) # 모니터할 값과 테스트 오차가 좋아지지 않아도 몇번까지 기다릴지 결정한다\n",
    "\n",
    "model.fit(x_train,y_train,epochs=1000, batch_size=100, callbacks=[Early_Stopping_callbacks])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n",
      "실제가격:19.4, 예상가격:23.4\n",
      "실제가격:10.9, 예상가격:17.5\n",
      "실제가격:34.7, 예상가격:26.6\n",
      "실제가격:15.6, 예상가격:19.5\n",
      "실제가격:22.6, 예상가격:24.1\n",
      "실제가격:29.0, 예상가격:26.5\n",
      "실제가격:23.8, 예상가격:25.2\n",
      "실제가격:45.4, 예상가격:30.4\n",
      "실제가격:50.0, 예상가격:23.9\n",
      "실제가격:26.7, 예상가격:25.1\n",
      "실제가격:16.4, 예상가격:15.8\n",
      "실제가격:25.0, 예상가격:23.6\n",
      "실제가격:32.5, 예상가격:31.0\n",
      "실제가격:50.0, 예상가격:20.6\n",
      "실제가격:35.4, 예상가격:29.7\n",
      "실제가격:34.9, 예상가격:35.8\n",
      "실제가격:25.0, 예상가격:14.2\n",
      "실제가격:22.0, 예상가격:25.4\n",
      "실제가격:10.2, 예상가격:16.9\n",
      "실제가격:50.0, 예상가격:18.2\n"
     ]
    }
   ],
   "source": [
    "# 예측값과 실제 값의 비교\n",
    "\n",
    "y_prediction=model.predict(x_test).flatten() # x_test의 예측 가격을 flatten()을 하면 모두 1차원으로 변환해 준다. 그러고 y_prediction에 넣어 준다\n",
    "\n",
    "for i in range(20): # 모두 비교해 볼 수 없으니까 20개만 비교해 보자. 그런데 df=df_pre.sample(frac=1)로 섞어주었기 때문에 실제 데이터 순서와는 다르다\n",
    "    label=y_test[i] # [중혁] 실제 y_test 가격을 소수점 1자리까지 label에 넣어 준다.\n",
    "    prediction=y_prediction[i]  # [중혁] y_test를 예측해 본 값이다\n",
    "    \n",
    "    print('실제가격:{:.1f}, 예상가격:{:.1f}'.format(label, prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d43fd8e729a9caee3dd2deedd9368c9e917ad35c69d2bc4126b3da226b1caf4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
