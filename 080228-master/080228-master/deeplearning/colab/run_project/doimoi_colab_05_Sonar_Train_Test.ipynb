{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       208 non-null    float64\n",
      " 1   1       208 non-null    float64\n",
      " 2   2       208 non-null    float64\n",
      " 3   3       208 non-null    float64\n",
      " 4   4       208 non-null    float64\n",
      " 5   5       208 non-null    float64\n",
      " 6   6       208 non-null    float64\n",
      " 7   7       208 non-null    float64\n",
      " 8   8       208 non-null    float64\n",
      " 9   9       208 non-null    float64\n",
      " 10  10      208 non-null    float64\n",
      " 11  11      208 non-null    float64\n",
      " 12  12      208 non-null    float64\n",
      " 13  13      208 non-null    float64\n",
      " 14  14      208 non-null    float64\n",
      " 15  15      208 non-null    float64\n",
      " 16  16      208 non-null    float64\n",
      " 17  17      208 non-null    float64\n",
      " 18  18      208 non-null    float64\n",
      " 19  19      208 non-null    float64\n",
      " 20  20      208 non-null    float64\n",
      " 21  21      208 non-null    float64\n",
      " 22  22      208 non-null    float64\n",
      " 23  23      208 non-null    float64\n",
      " 24  24      208 non-null    float64\n",
      " 25  25      208 non-null    float64\n",
      " 26  26      208 non-null    float64\n",
      " 27  27      208 non-null    float64\n",
      " 28  28      208 non-null    float64\n",
      " 29  29      208 non-null    float64\n",
      " 30  30      208 non-null    float64\n",
      " 31  31      208 non-null    float64\n",
      " 32  32      208 non-null    float64\n",
      " 33  33      208 non-null    float64\n",
      " 34  34      208 non-null    float64\n",
      " 35  35      208 non-null    float64\n",
      " 36  36      208 non-null    float64\n",
      " 37  37      208 non-null    float64\n",
      " 38  38      208 non-null    float64\n",
      " 39  39      208 non-null    float64\n",
      " 40  40      208 non-null    float64\n",
      " 41  41      208 non-null    float64\n",
      " 42  42      208 non-null    float64\n",
      " 43  43      208 non-null    float64\n",
      " 44  44      208 non-null    float64\n",
      " 45  45      208 non-null    float64\n",
      " 46  46      208 non-null    float64\n",
      " 47  47      208 non-null    float64\n",
      " 48  48      208 non-null    float64\n",
      " 49  49      208 non-null    float64\n",
      " 50  50      208 non-null    float64\n",
      " 51  51      208 non-null    float64\n",
      " 52  52      208 non-null    float64\n",
      " 53  53      208 non-null    float64\n",
      " 54  54      208 non-null    float64\n",
      " 55  55      208 non-null    float64\n",
      " 56  56      208 non-null    float64\n",
      " 57  57      208 non-null    float64\n",
      " 58  58      208 non-null    float64\n",
      " 59  59      208 non-null    float64\n",
      " 60  60      208 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 99.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.random(seed)\n",
    "tf.random.set_seed(3)\n",
    "df=pd.read_csv('C:/Users/doimo/pythonDataWorkspace/080228-master/080228-master/deeplearning/dataset/sonar.csv', header=None) #  read_csv 의 인자중 header 를 None 으로 주면 판다스는 인덱스를 자동으로 만들어낸다.\n",
    "\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 2)\n"
     ]
    }
   ],
   "source": [
    "dataset=df.values # 다른 곳에서는 values를 안 해도 되었는데 여기서는 왜 꼭 해 줘야 하는지 모르겠다\n",
    "ind=dataset[:,0:60].astype(float)\n",
    "sub=dataset[:,60]\n",
    "\n",
    "sub=pd.get_dummies(sub)\n",
    "print(sub.shape) # [중혁] onehot을 해서 y_obj가 한개가 아니라 문자  개수만큼 변한다 (208, 2)가 된다. 그렇기 때문에 y가 2가 되어야 한다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습셋과 테스트셋의 구분\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(ind,sub,test_size=0.3,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.keras.layers.Input(shape=[60])\n",
    "h=tf.keras.layers.Dense(8,activation='swish')(x)\n",
    "h=tf.keras.layers.Dense(8,activation='swish')(h)\n",
    "h=tf.keras.layers.Dense(8,activation='swish')(h)\n",
    "y=tf.keras.layers.Dense(2,activation='sigmoid')(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 1s 858us/step - loss: 0.6957 - accuracy: 0.4690\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.6908 - accuracy: 0.5517\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.6880 - accuracy: 0.6345\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.6820 - accuracy: 0.6828\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 858us/step - loss: 0.6750 - accuracy: 0.6759\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.6612 - accuracy: 0.6897\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.6449 - accuracy: 0.6966\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 858us/step - loss: 0.6243 - accuracy: 0.7241\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 858us/step - loss: 0.6019 - accuracy: 0.7034\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 981us/step - loss: 0.5803 - accuracy: 0.7517\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 858us/step - loss: 0.5557 - accuracy: 0.7448\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 929us/step - loss: 0.5363 - accuracy: 0.7655\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.5172 - accuracy: 0.7517\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.4918 - accuracy: 0.7931\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.4748 - accuracy: 0.8207\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.4564 - accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 858us/step - loss: 0.4389 - accuracy: 0.8276\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.4211 - accuracy: 0.8483\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.4332 - accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.4039 - accuracy: 0.8345\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.3931 - accuracy: 0.8552\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.3895 - accuracy: 0.8414\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.3810 - accuracy: 0.8345\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 715us/step - loss: 0.3740 - accuracy: 0.8483\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.3705 - accuracy: 0.8552\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.3639 - accuracy: 0.8552\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 894us/step - loss: 0.3556 - accuracy: 0.8621\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.3549 - accuracy: 0.8690\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.3537 - accuracy: 0.8690\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.3687 - accuracy: 0.8414\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.3643 - accuracy: 0.8276\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.3443 - accuracy: 0.8690\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.3389 - accuracy: 0.8621\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.3419 - accuracy: 0.8483\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.3371 - accuracy: 0.8759\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.3280 - accuracy: 0.8828\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.3284 - accuracy: 0.8759\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.3287 - accuracy: 0.8690\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.3245 - accuracy: 0.8759\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.3324 - accuracy: 0.8690\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.3328 - accuracy: 0.8690\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.3230 - accuracy: 0.8828\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.3392 - accuracy: 0.8552\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.3197 - accuracy: 0.8621\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.3114 - accuracy: 0.8621\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.3157 - accuracy: 0.8759\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.3154 - accuracy: 0.8690\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.3073 - accuracy: 0.8759\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.2999 - accuracy: 0.8897\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.3045 - accuracy: 0.8966\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.2981 - accuracy: 0.8828\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.2982 - accuracy: 0.9034\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.2992 - accuracy: 0.8966\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.2903 - accuracy: 0.8759\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 858us/step - loss: 0.2924 - accuracy: 0.9103\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.2925 - accuracy: 0.9103\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.3062 - accuracy: 0.8621\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.2836 - accuracy: 0.8759\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.2824 - accuracy: 0.8897\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 858us/step - loss: 0.2764 - accuracy: 0.9034\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.2751 - accuracy: 0.8966\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.2839 - accuracy: 0.8966\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.2751 - accuracy: 0.9103\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 858us/step - loss: 0.2691 - accuracy: 0.8966\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.2853 - accuracy: 0.9103\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.2775 - accuracy: 0.8966\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.2577 - accuracy: 0.9034\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.2671 - accuracy: 0.9034\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.2597 - accuracy: 0.8966\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 858us/step - loss: 0.2860 - accuracy: 0.8966\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 858us/step - loss: 0.2528 - accuracy: 0.9172\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.2603 - accuracy: 0.8897\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.2653 - accuracy: 0.8966\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.2555 - accuracy: 0.8897\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.2461 - accuracy: 0.9172\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.2706 - accuracy: 0.8828\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.2459 - accuracy: 0.8897\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.2383 - accuracy: 0.8966\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.2421 - accuracy: 0.9034\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.2379 - accuracy: 0.8966\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.2347 - accuracy: 0.9034\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.2679 - accuracy: 0.8897\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.2573 - accuracy: 0.8897\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.2348 - accuracy: 0.8966\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.2242 - accuracy: 0.9103\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 858us/step - loss: 0.2270 - accuracy: 0.9034\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.2143 - accuracy: 0.9241\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.2136 - accuracy: 0.9034\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.2076 - accuracy: 0.9103\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 894us/step - loss: 0.2163 - accuracy: 0.9103\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.2212 - accuracy: 0.9103\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.2156 - accuracy: 0.9172\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.2114 - accuracy: 0.8966\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 929us/step - loss: 0.1994 - accuracy: 0.9241\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.1927 - accuracy: 0.9310\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.1899 - accuracy: 0.9310\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.1911 - accuracy: 0.9172\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.1905 - accuracy: 0.9172\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 786us/step - loss: 0.1811 - accuracy: 0.9241\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.1786 - accuracy: 0.9310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ab5ba87220>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=tf.keras.models.Model(x,y)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics='accuracy')\n",
    "model.fit(x_train,y_train,epochs=100,batch_size=5) # epoch마다 하위에 n/n으로 나오는 숫자가 있을 것이다. 그 n이 epoch에서 사용하는 batch의 개수이다. batch의 개수는 epoch 내부에서 사용할 data의 수를 batch_size로 나눈 것이다. 총 batch의 개수는 150000/batch_size가 된다.batch_size가 10이라면 15000개의 batch가 생기는 것이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장과 재사용\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('my_model.h5')\n",
    "\n",
    "del model # 테스트를 위해 메모리 내의 모델을 삭제\n",
    "\n",
    "model = load_model('my_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d43fd8e729a9caee3dd2deedd9368c9e917ad35c69d2bc4126b3da226b1caf4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
